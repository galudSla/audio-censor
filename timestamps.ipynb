{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxIZcRJwAnF8PcgmXThwl6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/galudSla/audio-censor/blob/main/timestamps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c11NZQPnKw3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "362dc17c-51eb-4198-f4c3-e42e2ccaa4c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vosk\n",
            "  Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from vosk) (1.17.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vosk) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vosk) (4.66.5)\n",
            "Collecting srt (from vosk)\n",
            "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting websockets (from vosk)\n",
            "  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->vosk) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2024.8.30)\n",
            "Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: srt\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22428 sha256=4ce072c13ddb2ec6f20a46aabfbd75694a2d370dde9f1ce21f192fef826b55cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/31/a1/18e1e7e8bfdafd19e6803d7eb919b563dd11de380e4304e332\n",
            "Successfully built srt\n",
            "Installing collected packages: websockets, srt, vosk\n",
            "Successfully installed srt-3.5.3 vosk-0.3.45 websockets-13.1\n"
          ]
        }
      ],
      "source": [
        "pip install vosk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://alphacephei.com/vosk/models/vosk-model-en-us-0.22.zip\n",
        "!unzip vosk-model-en-us-0.22.zip"
      ],
      "metadata": {
        "id": "H_w-DqUMQMv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45e10ef1-0884-4951-9067-c09bb389e32b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-21 17:17:51--  https://alphacephei.com/vosk/models/vosk-model-en-us-0.22.zip\n",
            "Resolving alphacephei.com (alphacephei.com)... 188.40.21.16, 2a01:4f8:13a:279f::2\n",
            "Connecting to alphacephei.com (alphacephei.com)|188.40.21.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1913365522 (1.8G) [application/zip]\n",
            "Saving to: ‘vosk-model-en-us-0.22.zip’\n",
            "\n",
            "vosk-model-en-us-0. 100%[===================>]   1.78G  19.2MB/s    in 96s     \n",
            "\n",
            "2024-10-21 17:19:27 (19.0 MB/s) - ‘vosk-model-en-us-0.22.zip’ saved [1913365522/1913365522]\n",
            "\n",
            "Archive:  vosk-model-en-us-0.22.zip\n",
            "   creating: vosk-model-en-us-0.22/\n",
            "   creating: vosk-model-en-us-0.22/am/\n",
            "  inflating: vosk-model-en-us-0.22/am/final.mdl  \n",
            "  inflating: vosk-model-en-us-0.22/am/tree  \n",
            "   creating: vosk-model-en-us-0.22/ivector/\n",
            "  inflating: vosk-model-en-us-0.22/ivector/final.dubm  \n",
            "  inflating: vosk-model-en-us-0.22/ivector/final.ie  \n",
            "  inflating: vosk-model-en-us-0.22/ivector/final.mat  \n",
            "  inflating: vosk-model-en-us-0.22/ivector/splice.conf  \n",
            "  inflating: vosk-model-en-us-0.22/ivector/global_cmvn.stats  \n",
            "  inflating: vosk-model-en-us-0.22/ivector/online_cmvn.conf  \n",
            "  inflating: vosk-model-en-us-0.22/README  \n",
            "   creating: vosk-model-en-us-0.22/conf/\n",
            "  inflating: vosk-model-en-us-0.22/conf/mfcc.conf  \n",
            "  inflating: vosk-model-en-us-0.22/conf/model.conf  \n",
            "   creating: vosk-model-en-us-0.22/graph/\n",
            "  inflating: vosk-model-en-us-0.22/graph/disambig_tid.int  \n",
            "   creating: vosk-model-en-us-0.22/graph/phones/\n",
            " extracting: vosk-model-en-us-0.22/graph/phones/optional_silence.int  \n",
            " extracting: vosk-model-en-us-0.22/graph/phones/optional_silence.csl  \n",
            "  inflating: vosk-model-en-us-0.22/graph/phones/align_lexicon.int  \n",
            "  inflating: vosk-model-en-us-0.22/graph/phones/silence.csl  \n",
            "  inflating: vosk-model-en-us-0.22/graph/phones/align_lexicon.txt  \n",
            " extracting: vosk-model-en-us-0.22/graph/phones/optional_silence.txt  \n",
            "  inflating: vosk-model-en-us-0.22/graph/phones/disambig.txt  \n",
            "  inflating: vosk-model-en-us-0.22/graph/phones/word_boundary.int  \n",
            "  inflating: vosk-model-en-us-0.22/graph/phones/disambig.int  \n",
            "  inflating: vosk-model-en-us-0.22/graph/phones/word_boundary.txt  \n",
            "  inflating: vosk-model-en-us-0.22/graph/HCLG.fst  \n",
            " extracting: vosk-model-en-us-0.22/graph/num_pdfs  \n",
            "  inflating: vosk-model-en-us-0.22/graph/phones.txt  \n",
            "  inflating: vosk-model-en-us-0.22/graph/words.txt  \n",
            "   creating: vosk-model-en-us-0.22/rnnlm/\n",
            "  inflating: vosk-model-en-us-0.22/rnnlm/word_feats.txt  \n",
            "  inflating: vosk-model-en-us-0.22/rnnlm/special_symbol_opts.conf  \n",
            "  inflating: vosk-model-en-us-0.22/rnnlm/special_symbol_opts.txt  \n",
            "  inflating: vosk-model-en-us-0.22/rnnlm/feat_embedding.final.mat  \n",
            "  inflating: vosk-model-en-us-0.22/rnnlm/final.raw  \n",
            "   creating: vosk-model-en-us-0.22/rescore/\n",
            "  inflating: vosk-model-en-us-0.22/rescore/G.carpa  \n",
            "  inflating: vosk-model-en-us-0.22/rescore/G.fst  \n",
            "  inflating: vosk-model-en-us-0.22/conf/ivector.conf  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wave\n",
        "import sys\n",
        "\n",
        "from vosk import Model, KaldiRecognizer"
      ],
      "metadata": {
        "id": "N2g6L5I5LksA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/vosk-model-en-us-0.22\"\n",
        "audio_filename = \"/content/python_example_test.wav\""
      ],
      "metadata": {
        "id": "ew0zHnmoPzyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio1(model_path, audio_filename):\n",
        "    model = Model(model_path)\n",
        "\n",
        "    with wave.open(audio_filename, \"rb\") as wf:\n",
        "        rec = KaldiRecognizer(model, wf.getframerate())\n",
        "        rec.SetWords(True)\n",
        "\n",
        "        while True:\n",
        "            data = wf.readframes(4000)\n",
        "            if len(data) == 0:\n",
        "                break\n",
        "            if rec.AcceptWaveform(data):\n",
        "                pass\n",
        "                #print(rec.Result())\n",
        "            else:\n",
        "                pass\n",
        "                #print(rec.PartialResult())\n",
        "\n",
        "        final_result = rec.FinalResult()\n",
        "\n",
        "    del model\n",
        "    result_data = json.loads(final_result)\n",
        "\n",
        "    return result_data\n"
      ],
      "metadata": {
        "id": "_IhFpr_cn9Nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_result = transcribe_audio1(model_path, audio_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "collapsed": true,
        "id": "9JRmvegup_hR",
        "outputId": "49e43b62-ba74-4653-e9ae-662fce1339b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/python_example_test.wav'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ff950b2f092d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparsed_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscribe_audio1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-e7e8c1c59460>\u001b[0m in \u001b[0;36mtranscribe_audio1\u001b[0;34m(model_path, audio_filename)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mwave\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKaldiRecognizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetframerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mrec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetWords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/wave.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(f, mode)\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mWave_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mWave_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/wave.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# else, assume it is an open file object already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/python_example_test.wav'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(parsed_result['text'])\n",
        "info = {}\n",
        "for word_info in parsed_result['result']:\n",
        "    print(word_info['word'],word_info['start'],word_info['end'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8BVgvPjugm1",
        "outputId": "2de23955-f8bf-4d0d-819d-3a67a86909a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one zero zero zero one nine oh two one oh zero one eight zero three\n",
            "one 0.81 1.11\n",
            "zero 1.14 1.53\n",
            "zero 1.53 1.95\n",
            "zero 1.95 2.34\n",
            "one 2.34 2.61\n",
            "nine 3.93 4.17\n",
            "oh 4.17 4.29\n",
            "two 4.29 4.53\n",
            "one 4.53 4.68\n",
            "oh 4.68 4.98\n",
            "zero 6.24 6.69\n",
            "one 6.69 6.9\n",
            "eight 6.9 7.14\n",
            "zero 7.14 7.5\n",
            "three 7.5 8.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forbidden_words = ['one', 'three']\n"
      ],
      "metadata": {
        "id": "bH6mvZFNwDxo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}